{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "import ovs\n",
    "import uns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Process, Manager\n",
    "import datetime\n",
    "\n",
    "# Required imports for RandomSearch\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of personal functions\n",
    "def report_metric(test, pred):\n",
    "    print(\"Balanced accuracy of neural network is \\n\",\n",
    "        metrics.balanced_accuracy_score(test, pred))\n",
    "    print(\"Average_precision_score of neural network is \\n\",\n",
    "        metrics.average_precision_score(test, pred))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(test, pred))\n",
    "    print('Classification Report:\\n', classification_report(test, pred))\n",
    "        \n",
    "def print_train_test_stats(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    '''Print Statistics of recent predictions on training & test data'''\n",
    "    print('Training Error Statistics:')\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred_train))\n",
    "    print('Mean Absolute Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))\n",
    "    print('Confusion Matrix\\n', confusion_matrix(y_train, y_pred_train))\n",
    "    print('Classification Report:\\n', classification_report(y_train, y_pred_train))\n",
    "    print('Accuracy Score:', accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "    print('\\nTest Error Statistics:')\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "    print('Mean Absolute Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_test)))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_test))\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_test))\n",
    "    print('Accuracy Score:', accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "# Utility function to report best scores\n",
    "# Taken from https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data\n",
    "col_names=config.col_names2\n",
    "feature_cols=config.feature_cols2\n",
    "path_to_dataset=config.path_to_dataset2\n",
    "target=config.target2\n",
    "\n",
    "prob_data = pd.read_csv(path_to_dataset, header=None, names=col_names)\n",
    "prob_data.head()\n",
    "\n",
    "#split dataset in features and target variable\n",
    "X = prob_data[feature_cols] # Features\n",
    "y = prob_data[target] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling, Fit only to the feature X data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create Dataset Oversampling=False, normalization=False, standardization=True\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8,\n",
    "                                                    random_state=7,shuffle=True,stratify=y) # 80% training and 20% test\n",
    "# Scale input feature values\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imbalanced dataset Base Model Results with Adam Solver: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9466785248574876\n",
      "Average_precision_score of neural network is \n",
      " 0.8689057650147415\n",
      "Confusion Matrix:\n",
      " [[227441     10]\n",
      " [    42    352]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.97      0.89      0.93       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.99      0.95      0.97    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9029820883052151\n",
      "Average_precision_score of neural network is \n",
      " 0.7240116633104816\n",
      "Confusion Matrix:\n",
      " [[56855     9]\n",
      " [   19    79]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.90      0.81      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Base Model with Standardized data with Standard Scaler - what we are hoping to improve from the base\n",
    "print('\\nImbalanced dataset Base Model Results with Adam Solver: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(hidden_layer_sizes=(15,), random_state=7, max_iter=1000, alpha=1e-7,\n",
    "                          solver='adam',tol=1e-6,learning_rate='adaptive')\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch Round 1 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000e-06, 4.00000e-06, 1.60000e-05, 6.40000e-05, 2.56000e-04,\n",
       "       1.02400e-03, 4.09600e-03, 1.63840e-02, 6.55360e-02, 2.62144e-01])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 32*np.linspace(4,14, num=10, dtype=int)\n",
    "1e-6*np.logspace(0,9, base=4, num=10)\n",
    "# 200*np.linspace(1,10, num=10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 of RandomSearch Testing\n",
      "Testing started at: 2020-07-19 13:54:30.539604\n",
      "Top 3 Results of Round 1\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848 (std: 0.041)\n",
      "Parameters: {'max_iter': 1400, 'learning_rate_init': 0.001024, 'hidden_layer_sizes': 30, 'batch_size': 160, 'alpha': 0.0001}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.847 (std: 0.035)\n",
      "Parameters: {'max_iter': 600, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 50, 'batch_size': 384, 'alpha': 1.0000000000000001e-07}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.845 (std: 0.040)\n",
      "Parameters: {'max_iter': 800, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 25, 'batch_size': 448, 'alpha': 0.01}\n",
      "\n",
      "Training and Test Results of best model from current round\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9085942692136044\n",
      "Average_precision_score of neural network is \n",
      " 0.7788880765085405\n",
      "Confusion Matrix:\n",
      " [[227435     16]\n",
      " [    72    322]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.95      0.82      0.88       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.98      0.91      0.94    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8774806771329804\n",
      "Average_precision_score of neural network is \n",
      " 0.6818548825499605\n",
      "Confusion Matrix:\n",
      " [[56856     8]\n",
      " [   24    74]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.90      0.76      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.88      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Testing completed at: 2020-07-20 13:37:07.528148\n"
     ]
    }
   ],
   "source": [
    "# # Setup Model and parameters\n",
    "# NeuralNet = MLPClassifier(hidden_layer_sizes=(15,), random_state=7, max_iter=1000, solver='sgd',\n",
    "#                           tol=1e-6,learning_rate='adaptive') # Default we are comparing to\n",
    "print('Round 1 of RandomSearch Testing')\n",
    "print('Testing started at:', datetime.datetime.now())\n",
    "NeuralNet = MLPClassifier(random_state=7, solver='sgd',\n",
    "                          tol=1e-6,learning_rate='adaptive')\n",
    "param_dist = {'learning_rate_init': 1e-6*np.logspace(0,9, base=4, num=10),\n",
    "              'batch_size': 32*np.linspace(4,14, num=10, dtype=int),\n",
    "              'max_iter': 200*np.linspace(1,10, num=10, dtype=int),\n",
    "              'hidden_layer_sizes': 5*np.linspace(1,10, num=10, dtype=int),\n",
    "              'alpha': 1e-9*np.logspace(0,9, base=10, num=10)\n",
    "             }\n",
    "random_search = RandomizedSearchCV(NeuralNet, param_distributions=param_dist, scoring='average_precision',\n",
    "                                   n_iter=60, cv=5, random_state=7)\n",
    "clfsearch = random_search.fit(X_train,y_train)\n",
    "\n",
    "print('Top 3 Results of Round 1')\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# Give training and test results with the best found parameters\n",
    "print('Training and Test Results of best model from current round')\n",
    "y_train_pred = clfsearch.predict(X_train)\n",
    "y_train_score = clfsearch.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = clfsearch.predict(X_test)\n",
    "y_test_score = clfsearch.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)\n",
    "print('Testing completed at:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results of Round 1\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848 (std: 0.041)\n",
      "Parameters: {'max_iter': 1400, 'learning_rate_init': 0.001024, 'hidden_layer_sizes': 30, 'batch_size': 160, 'alpha': 0.0001}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.847 (std: 0.035)\n",
      "Parameters: {'max_iter': 600, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 50, 'batch_size': 384, 'alpha': 1.0000000000000001e-07}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.845 (std: 0.040)\n",
      "Parameters: {'max_iter': 800, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 25, 'batch_size': 448, 'alpha': 0.01}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.844 (std: 0.038)\n",
      "Parameters: {'max_iter': 200, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 40, 'batch_size': 224, 'alpha': 1e-08}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.843 (std: 0.036)\n",
      "Parameters: {'max_iter': 200, 'learning_rate_init': 0.004096, 'hidden_layer_sizes': 50, 'batch_size': 288, 'alpha': 1e-05}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top 5 results as I don't want to re-run this...\n",
    "print('Top 5 Results of Round 1')\n",
    "report(random_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch Round 2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-08, 5.99484250e-08, 3.59381366e-07, 2.15443469e-06,\n",
       "       1.29154967e-05, 7.74263683e-05, 4.64158883e-04, 2.78255940e-03,\n",
       "       1.66810054e-02, 1.00000000e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for determining new bounds of parameter values for random test\n",
    "# 32*np.linspace(4,14, num=10, dtype=int)\n",
    "# 1e-4*np.logspace(0,6, base=4, num=10)\n",
    "# 200*np.linspace(1,7, num=7, dtype=int)\n",
    "# 3*np.linspace(7,17, num=10, dtype=int)\n",
    "1e-8*np.logspace(0,7, base=10, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 of RandomSearch Testing\n",
      "Testing started at: 2020-07-20 15:40:52.119305\n",
      "Top 5 Results of Round 2\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.852 (std: 0.037)\n",
      "Parameters: {'max_iter': 800, 'learning_rate_init': 0.004031747359663594, 'hidden_layer_sizes': 51, 'batch_size': 448, 'alpha': 3.5938136638046275e-07}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.849 (std: 0.041)\n",
      "Parameters: {'max_iter': 1000, 'learning_rate_init': 0.0016, 'hidden_layer_sizes': 30, 'batch_size': 256, 'alpha': 2.1544346900318848e-06}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.847 (std: 0.040)\n",
      "Parameters: {'max_iter': 1200, 'learning_rate_init': 0.0016, 'hidden_layer_sizes': 24, 'batch_size': 224, 'alpha': 0.0027825594022071257}\n",
      "\n",
      "Training and Test Results of best model from Round 2\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9200309769402668\n",
      "Average_precision_score of neural network is \n",
      " 0.818140045119152\n",
      "Confusion Matrix:\n",
      " [[227442      9]\n",
      " [    63    331]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.97      0.84      0.90       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.99      0.92      0.95    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8826003037681026\n",
      "Average_precision_score of neural network is \n",
      " 0.7090205580025861\n",
      "Confusion Matrix:\n",
      " [[56858     6]\n",
      " [   23    75]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.93      0.77      0.84        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Testing completed at: 2020-07-21 08:09:28.462166\n"
     ]
    }
   ],
   "source": [
    "# # Setup Model and parameters\n",
    "# NeuralNet = MLPClassifier(hidden_layer_sizes=(15,), random_state=7, max_iter=1000, solver='sgd',\n",
    "#                           tol=1e-6,learning_rate='adaptive') # Default we are comparing to\n",
    "print('Round 2 of RandomSearch Testing')\n",
    "print('Testing started at:', datetime.datetime.now())\n",
    "NeuralNet = MLPClassifier(random_state=7, solver='sgd',\n",
    "                          tol=1e-6,learning_rate='adaptive')\n",
    "param_dist = {'learning_rate_init': 1e-4*np.logspace(0,6, base=4, num=10),\n",
    "              'batch_size': 32*np.linspace(4,14, num=10, dtype=int),\n",
    "              'max_iter': 200*np.linspace(1,7, num=7, dtype=int),\n",
    "              'hidden_layer_sizes': 3*np.linspace(7,17, num=10, dtype=int),\n",
    "              'alpha': 1e-8*np.logspace(0,7, base=10, num=10)\n",
    "             }\n",
    "random_search = RandomizedSearchCV(NeuralNet, param_distributions=param_dist, scoring='average_precision',\n",
    "                                   n_iter=60, cv=5, random_state=7)\n",
    "clfsearch2 = random_search.fit(X_train,y_train)\n",
    "\n",
    "print('Top 5 Results of Round 2')\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# Give training and test results with the best found parameters\n",
    "print('Training and Test Results of best model from Round 2')\n",
    "y_train_pred = clfsearch2.predict(X_train)\n",
    "y_train_score = clfsearch2.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = clfsearch2.predict(X_test)\n",
    "y_test_score = clfsearch2.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)\n",
    "print('Testing completed at:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results of Round 2\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.852 (std: 0.037)\n",
      "Parameters: {'max_iter': 800, 'learning_rate_init': 0.004031747359663594, 'hidden_layer_sizes': 51, 'batch_size': 448, 'alpha': 3.5938136638046275e-07}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.849 (std: 0.041)\n",
      "Parameters: {'max_iter': 1000, 'learning_rate_init': 0.0016, 'hidden_layer_sizes': 30, 'batch_size': 256, 'alpha': 2.1544346900318848e-06}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.847 (std: 0.040)\n",
      "Parameters: {'max_iter': 1200, 'learning_rate_init': 0.0016, 'hidden_layer_sizes': 24, 'batch_size': 224, 'alpha': 0.0027825594022071257}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.845 (std: 0.040)\n",
      "Parameters: {'max_iter': 200, 'learning_rate_init': 0.0256, 'hidden_layer_sizes': 36, 'batch_size': 128, 'alpha': 0.016681005372000592}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.845 (std: 0.038)\n",
      "Parameters: {'max_iter': 600, 'learning_rate_init': 0.0256, 'hidden_layer_sizes': 39, 'batch_size': 224, 'alpha': 0.016681005372000592}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top 5 results as I don't want to re-run this...\n",
    "print('Top 5 Results of Round 2')\n",
    "report(clfsearch2.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch Round 3 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for determining new bounds of parameter values for random testing round 3\n",
    "# 1e-4*np.logspace(0,6, base=4, num=10) # learning_rate_init\n",
    "# 22*np.linspace(11,20, num=10, dtype=int) # batch size\n",
    "# 100*np.linspace(6,12, num=7, dtype=int) # max iterations\n",
    "# 2*np.linspace(15,25, num=10, dtype=int) # hidden layer sizes\n",
    "# 1e-7*np.logspace(0,6, base=10, num=10) # l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 of RandomSearch Testing\n",
      "Testing started at: 2020-07-21 11:08:03.173000\n",
      "Top 5 Results of Round 3\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.854 (std: 0.040)\n",
      "Parameters: {'max_iter': 800, 'learning_rate_init': 0.0256, 'hidden_layer_sizes': 42, 'batch_size': 308, 'alpha': 0.021544346900318822}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.849 (std: 0.037)\n",
      "Parameters: {'max_iter': 1200, 'learning_rate_init': 0.004031747359663594, 'hidden_layer_sizes': 36, 'batch_size': 242, 'alpha': 0.004641588833612772}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.849 (std: 0.037)\n",
      "Parameters: {'max_iter': 700, 'learning_rate_init': 0.010159366732596474, 'hidden_layer_sizes': 42, 'batch_size': 308, 'alpha': 0.004641588833612772}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847 (std: 0.042)\n",
      "Parameters: {'max_iter': 600, 'learning_rate_init': 0.0256, 'hidden_layer_sizes': 40, 'batch_size': 242, 'alpha': 0.021544346900318822}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.846 (std: 0.034)\n",
      "Parameters: {'max_iter': 900, 'learning_rate_init': 0.004031747359663594, 'hidden_layer_sizes': 50, 'batch_size': 440, 'alpha': 2.154434690031883e-06}\n",
      "\n",
      "Training and Test Results of best model from Round 3\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8997176153096578\n",
      "Average_precision_score of neural network is \n",
      " 0.7681519145112033\n",
      "Confusion Matrix:\n",
      " [[227438     13]\n",
      " [    79    315]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.96      0.80      0.87       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.98      0.90      0.94    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8775334345893675\n",
      "Average_precision_score of neural network is \n",
      " 0.7356522679996474\n",
      "Confusion Matrix:\n",
      " [[56862     2]\n",
      " [   24    74]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.97      0.76      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.88      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Testing completed at: 2020-07-22 05:37:00.603909\n"
     ]
    }
   ],
   "source": [
    "# # Setup Model and parameters\n",
    "# NeuralNet = MLPClassifier(hidden_layer_sizes=(15,), random_state=7, max_iter=1000, solver='adam',\n",
    "#                           tol=1e-6,learning_rate='adaptive') # Default we are comparing to\n",
    "print('Round 3 of RandomSearch Testing')\n",
    "print('Testing started at:', datetime.datetime.now())\n",
    "NeuralNet = MLPClassifier(random_state=7, solver='sgd',\n",
    "                          tol=1e-6,learning_rate='adaptive')\n",
    "param_dist = {'learning_rate_init': 1e-4*np.logspace(0,6, base=4, num=10),\n",
    "              'batch_size': 22*np.linspace(11,20, num=10, dtype=int),\n",
    "              'max_iter': 100*np.linspace(6,12, num=7, dtype=int),\n",
    "              'hidden_layer_sizes': 2*np.linspace(15,25, num=10, dtype=int),\n",
    "              'alpha': 1e-7*np.logspace(0,6, base=10, num=10) \n",
    "             }\n",
    "random_search = RandomizedSearchCV(NeuralNet, param_distributions=param_dist, scoring='average_precision',\n",
    "                                   n_iter=60, cv=5, random_state=7)\n",
    "clfsearch3 = random_search.fit(X_train,y_train)\n",
    "\n",
    "print('Top 5 Results of Round 3')\n",
    "report(clfsearch3.cv_results_, n_top=5)\n",
    "\n",
    "# Give training and test results with the best found parameters\n",
    "print('Training and Test Results of best model from Round 3')\n",
    "y_train_pred = clfsearch3.predict(X_train)\n",
    "y_train_score = clfsearch3.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = clfsearch3.predict(X_test)\n",
    "y_test_score = clfsearch3.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)\n",
    "print('Testing completed at:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch Round 4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 700,  800,  900, 1000, 1100, 1200])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for determining new bounds of parameter values for random testing round 4\n",
    "# 1e-3*np.logspace(0,3, base=4, num=10) # learning_rate_init\n",
    "# 22*np.linspace(11,20, num=10, dtype=int) # batch size\n",
    "# 100*np.linspace(7,12, num=6, dtype=int) # max iterations\n",
    "# 2*np.linspace(18,25, num=8, dtype=int) # hidden layer sizes\n",
    "# 1e-4*np.logspace(0,3, base=10, num=10) # l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4 of RandomSearch Testing\n",
      "Testing started at: 2020-07-22 09:12:52.399294\n",
      "Top 5 Results of Round 4\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.854 (std: 0.037)\n",
      "Parameters: {'max_iter': 700, 'learning_rate_init': 0.016, 'hidden_layer_sizes': 46, 'batch_size': 264, 'alpha': 0.01}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.852 (std: 0.040)\n",
      "Parameters: {'max_iter': 900, 'learning_rate_init': 0.02539841683149118, 'hidden_layer_sizes': 46, 'batch_size': 242, 'alpha': 0.021544346900318825}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.852 (std: 0.040)\n",
      "Parameters: {'max_iter': 1000, 'learning_rate_init': 0.016, 'hidden_layer_sizes': 38, 'batch_size': 242, 'alpha': 0.021544346900318825}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.850 (std: 0.036)\n",
      "Parameters: {'max_iter': 900, 'learning_rate_init': 0.010079368399158984, 'hidden_layer_sizes': 46, 'batch_size': 396, 'alpha': 0.004641588833612777}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.850 (std: 0.036)\n",
      "Parameters: {'max_iter': 900, 'learning_rate_init': 0.004, 'hidden_layer_sizes': 46, 'batch_size': 418, 'alpha': 0.00046415888336127784}\n",
      "\n",
      "Training and Test Results of best model from Round 4\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9060671895259774\n",
      "Average_precision_score of neural network is \n",
      " 0.7855165560877307\n",
      "Confusion Matrix:\n",
      " [[227440     11]\n",
      " [    74    320]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.97      0.81      0.88       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.98      0.91      0.94    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8673205600473166\n",
      "Average_precision_score of neural network is \n",
      " 0.7057625670962884\n",
      "Confusion Matrix:\n",
      " [[56861     3]\n",
      " [   26    72]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.73      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Testing completed at: 2020-07-23 05:28:47.909508\n"
     ]
    }
   ],
   "source": [
    "# # Setup Model and parameters\n",
    "# NeuralNet = MLPClassifier(hidden_layer_sizes=(15,), random_state=7, max_iter=1000, solver='adam',\n",
    "#                           tol=1e-6,learning_rate='adaptive') # Default we are comparing to\n",
    "print('Round 4 of RandomSearch Testing')\n",
    "print('Testing started at:', datetime.datetime.now())\n",
    "NeuralNet = MLPClassifier(random_state=7, solver='sgd',\n",
    "                          tol=1e-6,learning_rate='adaptive')\n",
    "param_dist = {'learning_rate_init': 1e-3*np.logspace(0,3, base=4, num=10),\n",
    "              'batch_size': 22*np.linspace(11,20, num=10, dtype=int),\n",
    "              'max_iter': 100*np.linspace(7,12, num=6, dtype=int),\n",
    "              'hidden_layer_sizes': 2*np.linspace(18,25, num=8, dtype=int),\n",
    "              'alpha': 1e-4*np.logspace(0,3, base=10, num=10) \n",
    "             }\n",
    "random_search = RandomizedSearchCV(NeuralNet, param_distributions=param_dist, scoring='average_precision',\n",
    "                                   n_iter=60, cv=5, random_state=7)\n",
    "clfsearch4 = random_search.fit(X_train,y_train)\n",
    "\n",
    "print('Top 5 Results of Round 4')\n",
    "report(clfsearch4.cv_results_, n_top=5)\n",
    "\n",
    "# Give training and test results with the best found parameters\n",
    "print('Training and Test Results of best model from Round 4')\n",
    "y_train_pred = clfsearch4.predict(X_train)\n",
    "y_train_score = clfsearch4.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = clfsearch4.predict(X_test)\n",
    "y_test_score = clfsearch4.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)\n",
    "print('Testing completed at:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the top results from the Random Search Round 4\n",
    "As Rank 1 is already recorded above - testing for ranks 2 through 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 4 Rank 2 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8946282835236425\n",
      "Average_precision_score of neural network is \n",
      " 0.7442575299288101\n",
      "Confusion Matrix:\n",
      " [[227432     19]\n",
      " [    83    311]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.94      0.79      0.86       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.97      0.89      0.93    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8724226008636431\n",
      "Average_precision_score of neural network is \n",
      " 0.7159329814577424\n",
      "Confusion Matrix:\n",
      " [[56861     3]\n",
      " [   25    73]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.74      0.84        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 4 Rank 2 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=900, learning_rate_init=0.0253984, hidden_layer_sizes=(46,),\n",
    "                          batch_size=242, alpha=0.02154435,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 4 Rank 3 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8971707511409777\n",
      "Average_precision_score of neural network is \n",
      " 0.7538472753356625\n",
      "Confusion Matrix:\n",
      " [[227434     17]\n",
      " [    81    313]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.95      0.79      0.86       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.97      0.90      0.93    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8775158487705719\n",
      "Average_precision_score of neural network is \n",
      " 0.7168001927565947\n",
      "Confusion Matrix:\n",
      " [[56860     4]\n",
      " [   24    74]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.76      0.84        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 4 Rank 3 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=1000, learning_rate_init=0.016, hidden_layer_sizes=(38,),\n",
    "                          batch_size=242, alpha=0.02154435,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 4 Rank 4 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9276473884139088\n",
      "Average_precision_score of neural network is \n",
      " 0.8357463813569795\n",
      "Confusion Matrix:\n",
      " [[227443      8]\n",
      " [    57    337]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.98      0.86      0.91       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.99      0.93      0.96    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.867302974228521\n",
      "Average_precision_score of neural network is \n",
      " 0.6874429275521591\n",
      "Confusion Matrix:\n",
      " [[56859     5]\n",
      " [   26    72]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.73      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.87      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 4 Rank 4 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=900, learning_rate_init=0.01007937, hidden_layer_sizes=(46,),\n",
    "                          batch_size=396, alpha=0.00464159,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 4 Rank 5 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9263695597782237\n",
      "Average_precision_score of neural network is \n",
      " 0.8236398207042656\n",
      "Confusion Matrix:\n",
      " [[227439     12]\n",
      " [    58    336]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.97      0.85      0.91       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.98      0.93      0.95    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8724138079542454\n",
      "Average_precision_score of neural network is \n",
      " 0.7066408503879529\n",
      "Confusion Matrix:\n",
      " [[56860     4]\n",
      " [   25    73]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.74      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 4 Rank 5 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=900, learning_rate_init=0.004, hidden_layer_sizes=(46,),\n",
    "                          batch_size=418, alpha=0.000464159,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the top results from the Random Search 3\n",
    "As Rank 1 is already recorded above - testing for ranks 2 through 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 3 Rank 2 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9009910473939977\n",
      "Average_precision_score of neural network is \n",
      " 0.7753931770311058\n",
      "Confusion Matrix:\n",
      " [[227440     11]\n",
      " [    78    316]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.97      0.80      0.88       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.98      0.90      0.94    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.867302974228521\n",
      "Average_precision_score of neural network is \n",
      " 0.6874429275521591\n",
      "Confusion Matrix:\n",
      " [[56859     5]\n",
      " [   26    72]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.73      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.87      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 3 Rank 2 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=1200, learning_rate_init=0.00403175, hidden_layer_sizes=(36,),\n",
    "                          batch_size=242, alpha=0.00464159,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 3 Rank 3 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9251115156235916\n",
      "Average_precision_score of neural network is \n",
      " 0.8331098993746008\n",
      "Confusion Matrix:\n",
      " [[227444      7]\n",
      " [    59    335]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.98      0.85      0.91       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.99      0.93      0.96    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8877199304032248\n",
      "Average_precision_score of neural network is \n",
      " 0.7371209162714276\n",
      "Confusion Matrix:\n",
      " [[56860     4]\n",
      " [   22    76]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.78      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 3 Rank 3 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=700, learning_rate_init=0.01015937, hidden_layer_sizes=(42,),\n",
    "                          batch_size=308, alpha=0.00464159,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 3 Rank 4 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8984397866739725\n",
      "Average_precision_score of neural network is \n",
      " 0.7563742422416538\n",
      "Confusion Matrix:\n",
      " [[227434     17]\n",
      " [    80    314]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.95      0.80      0.87       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.97      0.90      0.93    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8826178895868984\n",
      "Average_precision_score of neural network is \n",
      " 0.72696022332019\n",
      "Confusion Matrix:\n",
      " [[56860     4]\n",
      " [   23    75]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.77      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 3 Rank 4 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=600, learning_rate_init=0.0256, hidden_layer_sizes=(40,),\n",
    "                          batch_size=242, alpha=0.0215443,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Random Search Round 3 Rank 5 Model: \n",
      "\n",
      "Training Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.9174951041499495\n",
      "Average_precision_score of neural network is \n",
      " 0.8154881014050128\n",
      "Confusion Matrix:\n",
      " [[227443      8]\n",
      " [    65    329]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.98      0.84      0.90       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.99      0.92      0.95    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "Test Data Performance Metrics:\n",
      "Balanced accuracy of neural network is \n",
      " 0.8877199304032248\n",
      "Average_precision_score of neural network is \n",
      " 0.7371209162714276\n",
      "Confusion Matrix:\n",
      " [[56860     4]\n",
      " [   22    76]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.95      0.78      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting Random Search Round 3 Rank 5 Model: \\n')\n",
    "\n",
    "# Create NN and fit and test it\n",
    "NeuralNet = MLPClassifier(max_iter=900, learning_rate_init=0.00403175, hidden_layer_sizes=(50,),\n",
    "                          batch_size=440, alpha=2.154437e-6,\n",
    "                          solver='sgd',tol=1e-6,learning_rate='adaptive', random_state=7)\n",
    "NNclf = NeuralNet.fit(X_train,y_train)\n",
    "y_train_pred = NNclf.predict(X_train)\n",
    "y_train_score = NNclf.predict_proba(X_train)\n",
    "# params = NNclf.get_params()\n",
    "print(\"Training Data Performance Metrics:\")\n",
    "report_metric(test=y_train, pred=y_train_pred)\n",
    "\n",
    "y_test_pred = NNclf.predict(X_test)\n",
    "y_test_score = NNclf.predict_proba(X_test)\n",
    "print(\"Test Data Performance Metrics:\")\n",
    "report_metric(test=y_test, pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
